{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 50: Semantic Segmentation\n",
    "\n",
    "## Dataset used: [DRIVE](https://www.isi.uu.nl/Research/Databases/DRIVE/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPath = 'DRIVE/training/'\n",
    "testPath = 'DRIVE/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying sample image, groundtruth and mask from the dataset\n",
    "sampleImg = np.array(Image.open(trainPath+'images/21_training.tif'))\n",
    "sampleGT = np.array(Image.open(trainPath+'1st_manual/21_manual1.gif'))\n",
    "sampleMask = np.array(Image.open(trainPath+'mask/21_training_mask.gif'))\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(131)\n",
    "plt.imshow(sampleImg)\n",
    "plt.title('Image')\n",
    "plt.subplot(132)\n",
    "plt.imshow(sampleGT,cmap='gray')\n",
    "plt.title('Ground Truth')\n",
    "plt.subplot(133)\n",
    "plt.imshow(sampleMask,cmap='gray')\n",
    "plt.title('Mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRIVE dataset has 20 images for training and 20 for testing\n",
    "TrainImages = torch.FloatTensor(600,3,224,224) # 20 images x 30 patches\n",
    "TrainLabels = torch.FloatTensor(600,224,224)\n",
    "TestImages = torch.FloatTensor(20,3,224,224)\n",
    "TestLabels = torch.FloatTensor(20,224,224)\n",
    "\n",
    "# Obtain list containing name of all files in the directoy\n",
    "trainImgList = os.listdir(trainPath+'images')\n",
    "testImgList = os.listdir(testPath+'images')\n",
    "\n",
    "# Preparing train data tensors\n",
    "img_no = 0\n",
    "for file in trainImgList:\n",
    "    imgNum = file.split('_')[0] # Image number from the filename\n",
    "    im = Image.open(trainPath+'images/'+ file)\n",
    "    seg = Image.open(trainPath+'1st_manual/'+str(imgNum)+'_manual1.gif')\n",
    "    mask = Image.open(trainPath+'mask/'+str(imgNum)+'_training_mask.gif')\n",
    "    im = np.array(im)\n",
    "    seg = np.array(seg)/255\n",
    "    mask = (np.array(mask)/255-seg)\n",
    "    idx = np.where(mask==1)\n",
    "    # Note: In the GT (seg), 0--> BG, 1--> Vessels, 2--> Tissue(mask)\n",
    "    seg[idx] = 2\n",
    "    \n",
    "    # Augmenting training data by taking 30 patches, each of size 224x224, from the original image\n",
    "    randIdx1 = np.random.randint(0,im.shape[0]-224,30) \n",
    "    randIdx2 = np.random.randint(0,im.shape[1]-224,30)\n",
    "    for p in range(30):\n",
    "        patch = im[randIdx1[p]:randIdx1[p]+224,randIdx2[p]:randIdx2[p]+224,:]/255\n",
    "        seg_patch = seg[randIdx1[p]:randIdx1[p]+224,randIdx2[p]:randIdx2[p]+224]\n",
    "        TrainImages[img_no] = torch.from_numpy(patch).transpose(0,2).unsqueeze(0)\n",
    "        TrainLabels[img_no] = torch.from_numpy(seg_patch).transpose(0,1).unsqueeze(0)\n",
    "        img_no += 1\n",
    "\n",
    "# Preparing test data tensors\n",
    "img_no = 0\n",
    "for file in testImgList:\n",
    "    imgNum = file.split('_')[0] # Image number from the filename\n",
    "    im = Image.open(testPath+'images/'+ file)\n",
    "    seg = Image.open(testPath+'1st_manual/'+str(imgNum)+'_manual1.gif')\n",
    "    mask = Image.open(testPath+'mask/'+str(imgNum)+'_test_mask.gif')\n",
    "    # Resizing the images to 224x224\n",
    "    im = np.array(im.resize((224,224)))/255\n",
    "    seg = np.array(seg.resize((224,224)))/255\n",
    "    mask = (np.array(mask.resize((224,224)))-seg)/255\n",
    "    idx = np.where(mask==1)\n",
    "    # Note: In the GT (seg), 0--> BG, 1--> Vessels, 2--> Tissue(mask)\n",
    "    seg[idx] = 2\n",
    "    TestImages[img_no] = torch.from_numpy(im).transpose(0,2).unsqueeze(0)\n",
    "    TestLabels[img_no] = torch.from_numpy(seg).transpose(0,1).unsqueeze(0)\n",
    "    img_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TrainImages.size())\n",
    "print(TrainLabels.size())\n",
    "print(TestImages.size())\n",
    "print(TestLabels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pytorch dataset\n",
    "trainDataset = TensorDataset(TrainImages, TrainLabels)\n",
    "testDataset = TensorDataset(TestImages, TestLabels)\n",
    "# Creating dataloader\n",
    "BatchSize = 10\n",
    "trainLoader = DataLoader(trainDataset, batch_size=BatchSize, shuffle=True,num_workers=4, pin_memory=True)\n",
    "testLoader = DataLoader(testDataset, batch_size=BatchSize, shuffle=False,num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegNet, self).__init__()        \n",
    "        \n",
    "        # Encoder\n",
    "        self.conv1c = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.mup1 = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
    "        self.conv1d = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1c(x))\n",
    "        x, idx1 = self.mp1(x)    \n",
    "        x = self.mup1(x, idx1)\n",
    "        x = self.conv1d(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SegNet()\n",
    "if use_gpu:\n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss2d() # 2D Negative Log-Likelihood\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations = 100\n",
    "trainLoss = []\n",
    "testLoss = []\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(iterations):\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0   \n",
    "    net.train(True) # For training\n",
    "    for data in trainLoader:\n",
    "        inputs,labels = data\n",
    "        # Wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), \\\n",
    "                Variable(labels.long().cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels.long())      \n",
    " \n",
    "        \n",
    "        # Feed-forward input data through the network\n",
    "        outputs = net(inputs)\n",
    "        # Compute loss/error\n",
    "        loss = criterion(F.log_softmax(outputs), labels)      \n",
    "        # Initialize gradients to zero\n",
    "        optimizer.zero_grad()                  \n",
    "        # Backpropagate loss and compute gradients\n",
    "        loss.backward()\n",
    "        # Update the network parameters\n",
    "        optimizer.step()\n",
    "        # Accumulate loss per batch\n",
    "        runningLoss += loss.data[0]          \n",
    "    avgTrainLoss = runningLoss/600.0    \n",
    "    trainLoss.append(avgTrainLoss)\n",
    "  \n",
    "    \n",
    "    # Evaluating performance on test set for each epoch\n",
    "    net.train(False) # For testing\n",
    "    test_runningLoss = 0    \n",
    "    for data in testLoader:\n",
    "        inputs,labels = data\n",
    "        # Wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), \\\n",
    "                Variable(labels.long().cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels.long())         \n",
    "        outputs = net(inputs)       \n",
    "         # Compute loss/error\n",
    "        loss = criterion(F.log_softmax(outputs), labels)      \n",
    "        # Accumulate loss per batch\n",
    "        test_runningLoss += loss.data[0] \n",
    "        \n",
    "    avgTestLoss = test_runningLoss/20.0    \n",
    "    testLoss.append(avgTestLoss)\n",
    "        \n",
    "    # Plotting Loss vs Epochs\n",
    "    fig1 = plt.figure(1)        \n",
    "    plt.plot(range(epoch+1),trainLoss,'r--',label='train')        \n",
    "    plt.plot(range(epoch+1),testLoss,'g--',label='test')        \n",
    "    if epoch==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')   \n",
    "      \n",
    "    \n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('At Iteration: {:.0f} /{:.0f}  ;  Training Loss: {:.6f}; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "          .format(epoch + 1,iterations,avgTrainLoss,epochEnd//60,epochEnd%60))\n",
    "    print('At Iteration: {:.0f} /{:.0f}  ;  Testing Loss: {:.6f} ; Time consumed: {:.0f}m {:.0f}s '\\\n",
    "          .format(epoch + 1,iterations,avgTestLoss,epochEnd//60,epochEnd%60))\n",
    "end = time.time()-start\n",
    "print('Training completed in {:.0f}m {:.0f}s'.format(end//60,end%60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing segmentation on one of the test images\n",
    "randIdx = np.random.randint(20)\n",
    "testImg = TestImages[randIdx]\n",
    "testLab = TestLabels[randIdx].numpy()\n",
    "\n",
    "# Feed-forward \n",
    "segImg = net(Variable(testImg).unsqueeze(0).cuda())\n",
    "# Applying softmax to get class probabilities\n",
    "segImg_np = F.softmax(segImg).data.cpu().squeeze(0).numpy()\n",
    "\n",
    "# Displaying segmented output and ground truth\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(231)\n",
    "plt.imshow(segImg_np[0,:,:],cmap='gray')\n",
    "plt.title('Channel 1')\n",
    "plt.subplot(232)\n",
    "plt.imshow(segImg_np[1,:,:],cmap='gray')\n",
    "plt.title('Channel 2')\n",
    "plt.subplot(233)\n",
    "plt.imshow(segImg_np[2,:,:],cmap='gray')\n",
    "plt.title('Channel 3')\n",
    "\n",
    "\n",
    "bg = testLab==0\n",
    "vessel = testLab==1\n",
    "tissue = testLab==2\n",
    "plt.subplot(234)\n",
    "plt.imshow(bg,cmap='gray')\n",
    "plt.title('Background')\n",
    "plt.subplot(235)\n",
    "plt.imshow(vessel,cmap='gray')\n",
    "plt.title('Vessel')\n",
    "plt.subplot(236)\n",
    "plt.imshow(tissue,cmap='gray')\n",
    "plt.title('Tissue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
