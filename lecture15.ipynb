{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 15: Retinal Vessel Detection using autoencoders\n",
    "## Dataset used: DRIVE [https://www.isi.uu.nl/Research/Databases/DRIVE/]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages:\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import struct\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Path:\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datapath = 'DRIVE/training/images/'\n",
    "Labelpath = 'DRIVE/training/1st_manual/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop Images:\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop random 10 x 10 patches from images and also crop corresponding label\n",
    "\n",
    "def img_transfer(img,imgLabel, bh, bw, no_of_patch):\n",
    "    \n",
    "    h = img.shape[0]\n",
    "    w = img.shape[1]\n",
    "    c = img.shape[2]\n",
    "    ImgArr = np.empty((no_of_patch, bh*bw*3))\n",
    "    LabelArr = np.empty((no_of_patch, bh*bw*1))\n",
    "\n",
    "    for i in range(no_of_patch):\n",
    "        ih = random.randint(0, h-bh)\n",
    "        iw = random.randint(0, w-bw)\n",
    "        iArrI = img[ih:ih+bh,iw:iw+bw,:]\n",
    "        iArrL = imgLabel[ih:ih+bh,iw:iw+bw,:]       \n",
    "        for ci in range(c):\n",
    "            for bhi in range(bh):\n",
    "                for bwi in range(bw):\n",
    "                    ImgArr[i][ci*bh*bw + bhi*bw + bwi] = iArrI[bhi][bwi][ci]\n",
    "                    if ci ==0:\n",
    "                        LabelArr[i][ci*bh*bw + bhi*bw + bwi] = iArrL[bhi][bwi][ci]\n",
    "        \n",
    "    return ImgArr,LabelArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patchH = 10 # height of the patch\n",
    "patchW = 10 # width of the patch\n",
    "PatchperImage = 1000 # no of patches per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainImages = torch.DoubleTensor(20*PatchperImage,3*patchH*patchW)\n",
    "TrainLabels = torch.LongTensor(20*PatchperImage,patchH*patchW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read each training image and crop random patches\n",
    "\n",
    "t_no = 0\n",
    "for img_no in range(20):\n",
    "    imD = Image.open(Datapath + str(img_no+21) + '_training.tif')\n",
    "    imD = np.array(imD)    \n",
    "    \n",
    "    imL = Image.open(Labelpath + str(img_no+21) + '_manual1.gif')\n",
    "    imL = np.array(imL)\n",
    "    imL = np.reshape(imL, (imL.shape[0],imL.shape[1],1))\n",
    "    \n",
    "    imD,imL = img_transfer(imD,imL, patchH, patchW, PatchperImage)\n",
    "    imD = imD/255.0\n",
    "    imL = imL/255.0\n",
    "    for i in range(PatchperImage):\n",
    "        TrainImages[t_no] = torch.from_numpy(imD[i])\n",
    "        TrainLabels[t_no] = torch.from_numpy(imL[i])\n",
    "        t_no = t_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing Training Image and labels size\n",
    "\n",
    "print(TrainImages.size())\n",
    "print(TrainLabels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('GPU is available!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Autoencoder:\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(patchH*patchW*3, patchH*patchW),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(patchH*patchW, patchH*patchW),\n",
    "            nn.Tanh())\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(patchH*patchW, patchH*patchW),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(patchH*patchW,patchH*patchW*3),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = autoencoder()\n",
    "print(net)\n",
    "\n",
    "if use_gpu:\n",
    "    net = net.double().cuda()\n",
    "else:\n",
    "    net = net.double()\n",
    "    \n",
    "init_weights = copy.deepcopy(net.encoder[0].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Optimization Technique:\n",
    "==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Autoencoder:\n",
    "==========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 500 #1000\n",
    "BatchSize = 1000\n",
    "trainLoss = []\n",
    "for epoch in range(iterations):\n",
    "    runningLoss = 0\n",
    "    for i in range(TrainImages.size()[0]/BatchSize):\n",
    "        inputs = torch.index_select(TrainImages,0,torch.linspace(i*BatchSize,(i+1)*BatchSize - 1,steps=BatchSize)\n",
    "                                  .long()).double()\n",
    "        if use_gpu:\n",
    "            inputs = Variable(inputs).cuda()\n",
    "        else:\n",
    "            inputs = Variable(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.data[0]\n",
    "    trainLoss.append(runningLoss/(TrainImages.size()[0]/BatchSize))\n",
    "    if epoch%100 == 0:\n",
    "        print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,iterations,runningLoss/\n",
    "                                                                (TrainImages.size()[0]/BatchSize)))\n",
    "print('Finished Training')\n",
    "\n",
    "\n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),trainLoss,'g-',label='Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training loss') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder Weights Visualization:\n",
    "=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to show an image\n",
    "\n",
    "def imshow(img, strlabel):\n",
    "    npimg = img.numpy()\n",
    "    npimg = np.abs(npimg)\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    fig_size[0] = 10\n",
    "    fig_size[1] = 10\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    plt.figure()\n",
    "    plt.title(strlabel)\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trained_weights = copy.deepcopy(net.encoder[0].weight.data)\n",
    "d_weights = init_weights - trained_weights \n",
    "\n",
    "if use_gpu:\n",
    "    init_weights = init_weights.view(100,3,10,10).cpu()\n",
    "    trained_weights = trained_weights.view(100,3,10,10).cpu()\n",
    "    d_weights = d_weights.view(100,3,10,10).cpu()\n",
    "else:\n",
    "    init_weights = init_weights.view(100,3,10,10)\n",
    "    trained_weights = trained_weights.view(100,3,10,10)\n",
    "    d_weights = d_weights.view(100,3,10,10)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(init_weights,nrow=10,normalize=True),'Initial Weights')\n",
    "imshow(torchvision.utils.make_grid(trained_weights,nrow=10,normalize=True),'Trained Weights')\n",
    "imshow(torchvision.utils.make_grid(d_weights,nrow=10,normalize=True), 'Weight update')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the autoencoder for classification:\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classifier = nn.Sequential(*list(net.children())[:-1])\n",
    "net = new_classifier\n",
    "net.add_module('classifier', nn.Sequential(nn.Linear(patchH*patchW, patchH*patchW),nn.Sigmoid()))\n",
    "print(net)\n",
    "if use_gpu:\n",
    "    net = net.double().cuda()\n",
    "else:\n",
    "    net = net.double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Classifier:\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "iterations = 500 #1000\n",
    "BatchSize = 1000\n",
    "trainLoss = []\n",
    "for epoch in range(iterations): # loop over the dataset multiple times\n",
    "    runningLoss = 0\n",
    "    for i in range(TrainImages.size()[0]/BatchSize):\n",
    "        inputs = torch.index_select(TrainImages,0,torch.linspace(i*BatchSize,(i+1)*BatchSize - 1,steps=BatchSize)\n",
    "                                  .long()).double()\n",
    "        labels = torch.index_select(TrainLabels,0,torch.linspace(i*BatchSize,(i+1)*BatchSize - 1,steps=BatchSize)\n",
    "                                  .long()).double()\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "        optimizer.zero_grad() # zeroes the gradient buffers of all parameters\n",
    "        outputs = net(inputs) # forward \n",
    "        loss = criterion(outputs, labels) # calculate loss\n",
    "        loss.backward() #  backpropagate the loss\n",
    "        optimizer.step()\n",
    "        runningLoss += loss.data[0]\n",
    "    trainLoss.append(runningLoss/(TrainImages.size()[0]/BatchSize))\n",
    "    if epoch%100 == 0:\n",
    "        print('At Iteration: %d / %d  ;  Training Loss: %f '%(epoch + 1,iterations,runningLoss/(TrainImages.size()[0]/BatchSize)))\n",
    "print('Finished Training')\n",
    "\n",
    "fig = plt.figure()        \n",
    "plt.plot(range(epoch+1),trainLoss,'g-',label='Loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training loss') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Performance:\n",
    "================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestDatapath = 'DRIVE/test/images/'  # Test Image Data Path\n",
    "TestLabelpath = 'DRIVE/test/1st_manual/'  # Test Image Manual Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Images and Convert Images into numpy array\n",
    "\n",
    "imD = Image.open(TestDatapath + '01_test.tif')\n",
    "imD = np.array(imD) \n",
    "imD = imD/255.0\n",
    "    \n",
    "imL = Image.open(TestLabelpath + '01_manual1.gif')\n",
    "imL = np.array(imL)\n",
    "imL = imL/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break the image into 10 x 10 patches and push the patches into the network for vessel detection\n",
    "\n",
    "TestArr = np.zeros(patchH*patchW*3)\n",
    "imout = np.zeros((imD.shape[0],imD.shape[1]))\n",
    "\n",
    "for i in range(imD.shape[0]/patchH):\n",
    "    for j in range(imD.shape[1]/patchW):\n",
    "        for l1 in range(3):\n",
    "            for l2 in range(patchH):\n",
    "                for l3 in range(patchW):\n",
    "                    TestArr[l1*patchH*patchW + l2*patchW + l3] = imD[i*patchH +l2][j*patchW+l3][l1]\n",
    "        TestTensor = torch.from_numpy(TestArr)\n",
    "        out = net(Variable(TestTensor.double().cuda()))\n",
    "        outArr = out.data.cpu().numpy()\n",
    "        for l2 in range(patchH):\n",
    "            for l3 in range(patchW):\n",
    "                imout[i*patchH +l2][j*patchW+l3] = outArr[l2*patchW + l3]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display results\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Input Image')\n",
    "plt.imshow(imD)\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Classifier Output')\n",
    "plt.imshow(imout, 'gray')\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Manual Label')\n",
    "plt.imshow(imL, 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
